Steps to setup K8-cluster in ubuntu Flavour (combination of worker nodes and master node is called as Kubernetes cluster)
========================================================================================================================
Initially check this and add the all 3 nodes
============================================

kubectl commands should only run in master node, not in worker nodes
====================================================================



1. sudo hostnamectl set-hostname k8master after this run this command sudo exec bash (run only in master node)
   Sudo hostnamectl set-hostname k8node1. after this run this command sudo exec bash. (run only in worker node1)
   Sudo hostnamectl set-hostname k8node2. after this run this command sudo exec bash. (run only in worker node2
   


2. go to vim /etc/hosts and add this in each node all 3 sub steps

example:  0.0.0.0       k8master.gonext.com       k8master
example:  1.1.1.1       k8node1.gonext.com       k8node1
example:  2.2.2.2.      k8node2.gonext.com       k8node2

This step because all the 3 nodes should communicate each other.
 
3. Pinging should do work and Enable ICMP V4 

4. Firewalld package should be installed in AWS Ubuntu OS, and Disabled.
   
   Sudo apt install firewalld
   Sudo systemctl status firewall
   Sudo systemctl stop firewall

5. SWAP memory will not support for K8, because cache memory will not required.

   sudo Free -m
   sudo Swappoff -a

6. SeLinux is disabled 
   sudo Sestatus
   sudo setenforce 0
   sudo Sestatus


7. sudo apt-get update && sudo apt-get install -y apt-transport-https curl

8. curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

9. sudo apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"

10. Sudo apt update

11. Install docker and enable the services in all 3 nodes
    Sudo apt install docker.io
    Sudo systemctl start docker
    Sudo systemctl enable docker

12. Install the Kubeadm, kubelet , kubectl  in all 3 nodes
    
   sudo apt-get install -y kubelet kubeadm kubectl 
   
13. Check the version kubeadm

14. Start the kubelet and enable the services of kubelet
    Sudo systemctl start kubelet
    Sudo systemctl enable kubelet


Only in Master node-Run the following commands and network add ons plugins in master node only.
================================================================================================

15. Add the environemnt details for Cgroup of dockers and kubelet for systems in a file kubernetes environmental file only in master node
file name: 10.kubeadm.conf 
path is: /etc/systemd/system/kubelet.service.d/10.kubeadm.conf
    
    Environment="cgroup-driver=systemd/cgroup-driver=cgroupfs"



16. sudo kubeadm init --apiserver-advertise-address **PROVIDE IP ADDRESS of master node** --pod-network-cidr=192.168.0.0/16
       Or
      sudo kubeadm init --pod-network-cidr=10.244.0.0/16

17. kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml


18.  mkdir -p $HOME/.kube
     sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
     sudo chown $(id -u):$(id -g) $HOME/.kube/config

19. Run kubectl get nodes. To verify all the 3 nodes are active or not.

20. Kubectl get pods --all-namespaces

21. Save the Generated token, with this token we have to join the worker nodes to master node
   example:  kubeadm join 172.31.45.220:6443 --token 4dpaz7.1d4qr7d06m46ta2n     --discovery-token-ca-cert-hash       sha256:94d0de44045b5a94507a3586ff68532fc7da62f45841c72d22622dbc9a5d23be 



In worker nodes
===============

1. 1 to 14 steps should run

2. kubeadm join generated token in master node.



Port numbers for master node and worker node details:
=====================================================
In master node these port numbers should be allowed
====================================================

Protocol	Direction	Port Range	Purpose	              Used By
==============================================================================
TCP	        Inbound	          6443*	     Kubernetes API server	All
TCP	        Inbound           2379-2380  etcd server client API	kube-apiserver, etcd
TCP	        Inbound	          10250	     Kubelet API	        Self, Control plane
TCP	        Inbound	          10251	    kube-scheduler	        Self
TCP	        Inbound	          10252	    kube-controller-manager	Self


In worker node these port numbers should be allowed
=====================================================
Protocol	Direction	Port Range	Purpose	              Used By
==============================================================================
TCP	        Inbound	        10250	        Kubelet API	        Self, Control plane
TCP	        Inbound	        30000-32767	NodePort Servicesâ€ 	All




Required Port numbers in master node for Kubernetes cluster only in Master node
===============================================================================
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10251/tcp
firewall-cmd --permanent --add-port=10252/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --reload
And additional port numbers if required

8080
8081
8082
8443
9090



Required Port numbers for only  in worker nodes
========================================
Enable the port numbers range from 
30000-32767

firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --permanent --add-port=130000/tcp

To
firewall-cmd --permanent --add-port=32767/tcp
firewall-cmd --reload



for installation:
     https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#control-plane-nodes
for services:
     https://kubernetes.io/docs/concepts/services-networking/service/
for network add ons: 
     https://kubernetes.io/docs/concepts/cluster-administration/addons/
     
  ################################################################################################################################################################   
     
     https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4
  
Steps to setup K8-cluster in centos Flavour (combination of worker nodes and master node is called as Kubernetes cluster)
========================================================================================================================
Initially check this and add the all 3 nodes
============================================

kubectl commands should only run in master node, not in worker nodes
====================================================================



1. sudo hostnamectl set-hostname k8master after this run this command sudo exec bash (run only in master node)
   Sudo hostnamectl set-hostname k8node1. after this run this command sudo exec bash. (run only in worker node1)
   Sudo hostnamectl set-hostname k8node2. after this run this command sudo exec bash. (run only in worker node2
   


2. go to vim /etc/hosts and add this in each node all 3 sub steps

example:  0.0.0.0       k8master.gonext.com       k8master
example:  1.1.1.1       k8node1.gonext.com       k8node1
example:  2.2.2.2.      k8node2.gonext.com       k8node2

This step because all the 3 nodes should communicate each other.
 
4. Firewalld package should be installed in AWS UBUNTU OS, and Disabled.
   
 ##install the package firewalld
   yum install firewalld -y 
   systemctl status firewalld
   systemctl start firewalld

5. SWAP memory will not support for K8, because cache memory will not required.

   free -m
   swappoff -a

6. SeLinux is disabled 
   sestatus
   setenforce 0
   sestatus

# setenforce 0
# sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
# echo '1' > /proc/sys/net/bridge/bridge-nf-call-iptables
  modprobe br_netfilter
  cho '1' > /proc/sys/net/bridge/bridge-nf-call-iptables

7. Pinging should do work and Enable ICMP V4 important:

create a filename with firewall.sh and add the line no 54 to 66 inside the file and run the firewall.sh file with following command bash firewall.sh

#!/bin/bash
set -x
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10259/tcp
firewall-cmd --permanent --add-port=10257/tcp
firewall-cmd --permanent --add-port=179/tcp
firewall-cmd --zone=public --add-port=53/tcp --permanent
firewall-cmd --zone=public --add-port=53/udp --permanent
firewall-cmd --add-masquerade --permanent
firewall-cmd --reload
set +x 

8. After above cmd run below command to open IPv4 and IPv6 Tables : iptables -w -P FORWARD ACCEPT

modprobe overlay
modprobe br_netfilter
tee /etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
sysctl --system

*****
### Update the apt package index and install packages needed to use the Kubernetes apt repository:
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
******

#### Download the Google Cloud public signing key:

 sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
 
 #### Add the Kubernetes apt repository:

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

# firewall-cmd --permanent --add-port=6783/tcp
# firewall-cmd --permanent --add-port=10250/tcp
# firewall-cmd --permanent --add-port=10255/tcp
# firewall-cmd --permanent --add-port=30000-32767/tcp
# firewall-cmd  --reload


11. Install docker and enable the services in all 3 nodes
    Sudo yum install docker.io
    Sudo systemctl start docker
    Sudo systemctl enable docker

12. ##### Update apt package index, install kubelet, kubeadm and kubectl, and pin their version:

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
   
13. Check the version kubeadm
     kubeadm version

14. Start the kubelet and enable the services of kubelet
    Sudo systemctl start kubelet
    Sudo systemctl enable kubelet
    
    


Only in Master node-Run the following commands and network add ons plugins in master node only.
================================================================================================

#15. Add the environemnt details for Cgroup of dockers and kubelet for systems in a file kubernetes environmental file only in #master node file name: 10.kubeadm.conf 
#path is: /etc/systemd/system/kubelet.service.d/10.kubeadm.conf
    
    #Environment="cgroup-driver=systemd/cgroup-driver=cgroupfs"
    
    systemctl restart docker && systemctl enable docker
    systemctl  restart kubelet && systemctl enable kubelet

16. sudo kubeadm init --apiserver-advertise-address **PROVIDE IP ADDRESS of master node** --pod-network-cidr=192.168.0.0/16
       Or
      sudo kubeadm init --pod-network-cidr=10.244.0.0/16

17.  ####   Your Kubernetes control-plane has initialized successfully!

     ####  To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

     ##### Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

18. #### You should now deploy a pod network to the cluster. you have below 2 commands 

     kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
       or
    ## Install Calico with Kubernetes API datastore, 50 nodes or less
    
    curl https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml -O     

19. ####  Save the Generated token, with this token we have to join the worker nodes to master node
   example:  kubeadm join 172.31.45.220:6443 --token 4dpaz7.1d4qr7d06m46ta2n --discovery-token-ca-cert-hash       sha256:94d0de44045b5a94507a3586ff68532fc7da62f45841c72d22622dbc9a5d23be
   
20. ####  if the  Generated token was missed , with the follwoing 2 methods you can get the token
       1). kubeadm join IP of master 
       2). kubeadm token list  or kubeadm token create 
       3). openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \
   openssl dgst -sha256 -hex | sed 's/^.* //'
   
       or 
       
    ####  simply write a below command
       
       kubeadm token create --print-join-command
   
21. Run kubectl get nodes. To verify all the 3 nodes are active or not.

      kubectl get pods --all-namespaces
      kubectl get nods
   
   kubeadm init --apiserver-advertise-address=10.46.176.28 --pod-network-cidr=192.168.1.0/16
   https://phoenixnap.com/kb/how-to-install-kubernetes-on-centos
   https://www.tecmint.com/install-kubernetes-cluster-on-centos-7/
